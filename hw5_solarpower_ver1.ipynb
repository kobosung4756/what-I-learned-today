{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5_solarpower_ver1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kobosung4756/what-I-learned-today/blob/main/hw5_solarpower_ver1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3bpvTNIRwWl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QICWFIJUR6PL"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yamyPUkE6Sh0"
      },
      "source": [
        "# device='cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPvXMU74ELZj"
      },
      "source": [
        "data=pd.read_csv('train.csv')\n",
        "data2=pd.read_csv('X_test.csv')\n",
        "submit=pd.read_csv('sample_submit.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfOiyoX_x6Ua"
      },
      "source": [
        "xy=np.array(data, dtype=np.float32)\n",
        "\n",
        "train_X = torch.FloatTensor(xy[:,0:-1])\n",
        "train_Y=torch.FloatTensor(xy[:,[-1]])\n",
        "# train_Y=torch.squeeze(train_Y, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sONZa9SfxyBS",
        "outputId": "9158beef-af5f-495b-fd38-feafced0be18"
      },
      "source": [
        "print(train_X)\n",
        "print(train_Y)\n",
        "print(train_X.shape)\n",
        "print(train_Y.shape)\n",
        "print(train_Y.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0.0000,   0.0000,   0.0000,  ...,   1.5000,  69.0800, -12.0000],\n",
            "        [  0.0000,   0.0000,  30.0000,  ...,   1.5000,  69.0600, -12.0000],\n",
            "        [  0.0000,   1.0000,   0.0000,  ...,   1.6000,  71.7800, -12.0000],\n",
            "        ...,\n",
            "        [208.0000,   6.0000,   0.0000,  ...,   1.1000,  47.4600,  15.0000],\n",
            "        [208.0000,   6.0000,  30.0000,  ...,   1.4000,  44.5100,  17.0000],\n",
            "        [208.0000,   7.0000,   0.0000,  ...,   1.7000,  37.8000,  19.0000]])\n",
            "tensor([[ 0.0000],\n",
            "        [ 0.0000],\n",
            "        [ 0.0000],\n",
            "        ...,\n",
            "        [13.8872],\n",
            "        [23.2699],\n",
            "        [33.0276]])\n",
            "torch.Size([9999, 8])\n",
            "torch.Size([9999, 1])\n",
            "tensor([0.0000e+00, 9.3828e-02, 9.3831e-02,  ..., 9.7288e+01, 9.7667e+01,\n",
            "        9.7850e+01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh_Yz21HVs0V"
      },
      "source": [
        "# 학습 파라미터 설정\n",
        "learning_rate = 0.001\n",
        "drop_prob = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntcrgdljaxST"
      },
      "source": [
        "linear1 = torch.nn.Linear(8,512,bias=True)\n",
        "linear2 = torch.nn.Linear(512,512,bias=True)\n",
        "linear3 = torch.nn.Linear(512,512,bias=True)\n",
        "linear4 = torch.nn.Linear(512,512,bias=True)\n",
        "linear5 = torch.nn.Linear(512,1,bias=True)\n",
        "relu = torch.nn.ReLU()\n",
        "dropout = torch.nn.Dropout(p=drop_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrpNg6XycEWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53718439-6a57-46ad-e1da-55176f182193"
      },
      "source": [
        "# Random Init => Xavier Init\n",
        "torch.nn.init.xavier_normal_(linear1.weight)\n",
        "torch.nn.init.xavier_normal_(linear2.weight)\n",
        "torch.nn.init.xavier_normal_(linear3.weight)\n",
        "torch.nn.init.xavier_normal_(linear4.weight)\n",
        "torch.nn.init.xavier_normal_(linear5.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.0177e-01, -3.5125e-02, -2.0119e-02,  2.5088e-02,  5.4480e-02,\n",
              "         -4.6233e-02, -5.4380e-02, -2.1184e-03, -7.2732e-02,  4.6227e-02,\n",
              "          2.5965e-02,  5.3083e-02, -3.8221e-03,  2.0609e-02,  7.5596e-03,\n",
              "          3.9848e-02, -7.2982e-02, -6.5854e-02,  3.4890e-02, -1.8343e-02,\n",
              "          3.3812e-02, -1.2580e-01,  1.3557e-01, -8.1427e-02, -1.3377e-02,\n",
              "          3.7150e-02, -4.4006e-02,  9.9063e-03,  5.2414e-02,  1.4235e-02,\n",
              "          4.1581e-02,  5.3383e-03,  1.4287e-02,  9.7459e-02, -3.8616e-02,\n",
              "          6.9806e-02,  2.8713e-02,  1.8915e-02, -8.3421e-02,  5.3672e-02,\n",
              "          3.8063e-02, -3.2953e-02,  1.6238e-02, -1.3073e-02, -2.8187e-03,\n",
              "         -2.1863e-02,  3.1670e-02, -1.6422e-02,  1.4516e-03,  8.0996e-04,\n",
              "         -3.0874e-02,  6.1301e-02, -3.1781e-02,  8.3663e-02, -1.2186e-01,\n",
              "          5.8655e-02, -1.5628e-02, -3.7894e-02, -4.1394e-02,  5.0144e-02,\n",
              "         -1.4037e-03,  6.4192e-02, -7.0164e-02,  1.7584e-02, -4.7895e-02,\n",
              "          1.8228e-03, -3.3639e-02,  3.7570e-02,  3.0168e-02, -1.2837e-01,\n",
              "          3.3823e-02,  1.7471e-02, -5.6678e-02, -3.9056e-02, -3.5798e-02,\n",
              "         -1.0264e-01, -5.1075e-02,  7.1885e-02,  2.0997e-02,  3.9022e-02,\n",
              "          6.0771e-02, -4.2210e-02,  1.7067e-02,  4.3026e-02,  1.0873e-01,\n",
              "          4.1060e-02, -4.8594e-02, -6.2218e-02, -3.2776e-02,  8.2153e-02,\n",
              "          5.6219e-04,  4.8774e-02,  1.3345e-01, -5.3541e-02, -3.1664e-02,\n",
              "          6.0966e-03, -4.6193e-02,  2.5561e-02, -5.7397e-02, -1.4931e-02,\n",
              "          2.4932e-02, -8.5517e-02,  2.5374e-02, -1.1982e-01,  7.0974e-02,\n",
              "          5.9989e-02, -8.9550e-03,  1.1172e-02, -6.9983e-02,  2.4195e-02,\n",
              "          3.0326e-02,  9.5606e-02, -6.8464e-02,  1.3086e-01, -3.1658e-02,\n",
              "          1.1239e-02, -1.0733e-01, -1.2500e-02,  4.1953e-02,  3.6279e-02,\n",
              "         -5.1743e-02, -4.5188e-03,  1.2601e-02,  5.0319e-03, -1.2771e-02,\n",
              "         -7.9758e-02, -1.3066e-02, -1.8262e-02,  1.4801e-02, -2.2214e-02,\n",
              "          4.4829e-02,  5.2393e-02, -2.4996e-02, -4.3247e-02,  6.1095e-02,\n",
              "         -2.0622e-02, -3.9282e-02,  1.7835e-02,  3.4806e-02, -1.2162e-01,\n",
              "          4.6077e-02, -3.7967e-02, -3.6142e-02, -1.1619e-02, -6.3386e-02,\n",
              "         -6.5553e-02, -4.9658e-02, -1.3657e-02, -9.6965e-02,  4.7780e-03,\n",
              "          8.5322e-02,  7.8525e-02,  4.2531e-02,  9.7181e-02, -1.4336e-02,\n",
              "          1.3056e-02,  4.8140e-02,  4.8950e-02, -5.3671e-03,  8.9596e-02,\n",
              "          4.3935e-02,  3.5719e-02, -2.3234e-02,  5.1157e-02,  6.5023e-02,\n",
              "         -1.2425e-02, -3.8754e-02,  8.4125e-02,  3.9731e-02,  5.4464e-02,\n",
              "          1.2521e-01,  1.3634e-01, -1.1280e-01, -5.3354e-02, -3.0033e-05,\n",
              "          2.3582e-02,  4.9408e-02, -3.2342e-04,  4.9615e-02, -4.5121e-02,\n",
              "         -8.4725e-03,  4.1050e-02, -3.6621e-02, -6.8070e-02,  1.0362e-01,\n",
              "         -4.1098e-02, -9.6753e-02,  3.1607e-02, -3.2405e-02,  6.2845e-02,\n",
              "          3.0139e-03, -6.7909e-02,  1.2003e-02, -2.5487e-03,  2.0326e-02,\n",
              "          1.4875e-03,  7.5405e-02, -1.2290e-01,  8.1374e-02,  5.7340e-02,\n",
              "         -4.2366e-02,  3.6201e-02,  6.5454e-03, -6.5738e-02,  1.9178e-02,\n",
              "          2.5810e-02,  4.1736e-02, -2.1038e-02,  6.0272e-02,  5.2607e-02,\n",
              "          4.8407e-03,  8.5642e-02,  1.5618e-02,  7.2554e-02,  1.5315e-02,\n",
              "         -2.3343e-02,  2.5463e-02,  5.6091e-02, -2.9575e-02,  2.1383e-02,\n",
              "          8.2065e-02,  4.9224e-02, -5.7725e-02,  1.1464e-01, -7.6475e-02,\n",
              "          1.1452e-02, -7.7915e-03, -8.6050e-02, -1.0738e-02,  1.5966e-02,\n",
              "         -8.8619e-02, -2.3403e-02, -2.3325e-02, -5.5494e-02,  2.8164e-02,\n",
              "         -9.7835e-02, -3.8487e-02, -1.4583e-03,  4.6643e-02,  6.4977e-02,\n",
              "         -7.9615e-02,  1.3958e-02, -5.8028e-02, -9.1375e-02, -2.8176e-02,\n",
              "         -2.7912e-02,  1.4597e-02, -3.9377e-02,  1.3867e-01,  1.0275e-01,\n",
              "         -2.9542e-03, -4.4320e-02, -5.6053e-02,  6.9935e-03,  8.6673e-03,\n",
              "         -2.3821e-02,  4.3501e-02, -5.4540e-03,  6.1482e-02,  6.5020e-02,\n",
              "          1.1928e-01,  9.6057e-03,  3.4890e-02,  1.2507e-01, -3.2004e-02,\n",
              "         -7.9409e-02, -1.3529e-02, -7.2712e-02,  4.8278e-02, -6.9825e-02,\n",
              "          6.8708e-02, -4.2305e-02,  2.3545e-02,  1.6362e-02,  3.3209e-02,\n",
              "          1.2173e-02, -2.3635e-02, -8.0355e-02,  1.0249e-01, -1.5353e-03,\n",
              "         -8.4040e-02,  5.5557e-02, -6.8222e-02,  1.4819e-02,  4.5085e-02,\n",
              "         -2.4866e-03,  8.2686e-02, -7.3410e-03,  1.9013e-02, -9.7496e-02,\n",
              "         -3.2325e-02,  1.2242e-02,  8.8503e-03,  8.2822e-02, -8.3156e-02,\n",
              "          8.3929e-02, -1.5610e-02,  3.7011e-02, -3.3487e-02, -6.7442e-02,\n",
              "         -9.0298e-03, -7.9476e-02, -8.4584e-02,  1.0374e-01,  3.3336e-02,\n",
              "          5.7239e-03, -3.5462e-02, -2.0690e-02,  1.5418e-02, -9.1450e-02,\n",
              "          1.9367e-02, -5.2350e-02,  2.2479e-02, -3.2933e-03,  1.1969e-01,\n",
              "         -5.6648e-02,  3.0912e-02,  7.2999e-02, -8.0321e-02,  5.5760e-02,\n",
              "         -8.6499e-02,  7.1086e-04,  5.7626e-02, -4.5370e-03, -1.8523e-02,\n",
              "         -8.3805e-02, -9.7244e-02,  1.2264e-01, -3.7441e-02,  3.7264e-03,\n",
              "          2.7877e-02, -2.8374e-02,  5.5872e-02, -3.6464e-02, -6.6716e-04,\n",
              "         -7.5363e-02, -1.1596e-01,  1.4839e-01, -1.1316e-02,  5.3147e-02,\n",
              "          6.6728e-02,  5.5872e-02, -1.2709e-02,  2.9431e-02, -7.6960e-02,\n",
              "          7.7687e-02, -3.3461e-02, -6.7640e-02, -8.1894e-03,  1.7834e-02,\n",
              "          7.9463e-02,  8.3565e-03, -2.4403e-02,  1.3672e-03,  2.0559e-02,\n",
              "         -1.1058e-01,  8.2676e-02,  4.8739e-02,  6.1580e-02,  1.6340e-01,\n",
              "          2.6251e-02, -2.5918e-02, -3.0303e-02,  9.7220e-02, -1.1093e-01,\n",
              "         -1.6083e-02,  7.5834e-03,  9.8671e-03, -3.1753e-02,  1.4629e-02,\n",
              "         -7.7349e-02, -1.3683e-02, -1.1722e-01,  7.4285e-02, -4.3302e-02,\n",
              "          9.0435e-02,  5.3047e-02,  1.7037e-02, -3.2759e-02,  1.3122e-01,\n",
              "          1.1218e-01,  1.1068e-02, -4.8032e-02, -7.8167e-03,  7.2590e-02,\n",
              "         -3.7788e-02, -6.0004e-03, -5.8444e-02, -1.1385e-02, -4.3659e-02,\n",
              "          1.3051e-02,  8.5918e-02, -1.9132e-02,  5.4237e-02,  3.2584e-02,\n",
              "          3.2385e-02, -8.3696e-02,  5.5777e-02, -6.2303e-02, -4.5796e-02,\n",
              "          7.5121e-02,  6.0596e-02,  5.0838e-02, -4.2516e-02,  1.5512e-02,\n",
              "         -2.9465e-02,  8.3349e-02, -1.7713e-01,  7.4441e-05, -3.5732e-05,\n",
              "          6.1992e-02, -1.5955e-02,  6.4885e-02,  4.3676e-02, -9.7288e-02,\n",
              "         -2.7941e-02,  5.0536e-02, -8.5193e-02,  4.9090e-02, -4.7875e-02,\n",
              "          3.3405e-02,  5.5641e-02, -3.3449e-02, -1.3881e-02, -1.0752e-02,\n",
              "         -1.1303e-01, -5.5568e-02, -2.0056e-02,  1.8716e-02,  7.3443e-04,\n",
              "          8.0338e-02, -5.6420e-02, -2.9003e-02,  1.0376e-01, -6.0562e-02,\n",
              "         -8.1835e-02, -1.5949e-02,  5.6401e-04,  1.4136e-03, -1.3374e-02,\n",
              "          5.8049e-02, -1.7491e-02, -7.3857e-02, -1.3002e-02, -5.5373e-02,\n",
              "          7.5761e-02,  4.9957e-02, -7.4627e-02, -1.2214e-02,  3.7721e-03,\n",
              "          5.0602e-02, -5.2156e-02, -1.1478e-01,  3.4709e-02,  4.5213e-02,\n",
              "         -7.0109e-02,  1.7942e-02, -1.9013e-02, -1.6204e-02,  4.4298e-02,\n",
              "         -7.6350e-02,  5.3313e-02,  6.2129e-02,  1.0436e-01, -1.1743e-02,\n",
              "         -5.0590e-02, -1.4104e-03,  1.2239e-02, -8.1555e-03,  4.4028e-02,\n",
              "          5.3777e-02,  3.8403e-02, -7.8617e-02, -1.0283e-01, -1.8544e-03,\n",
              "          1.0448e-01,  7.6558e-02, -8.2300e-02,  2.3831e-02, -1.2923e-01,\n",
              "          5.3217e-02, -3.1988e-02,  9.9214e-03,  7.3719e-02, -8.8069e-03,\n",
              "          4.6648e-02, -7.0580e-02, -7.1047e-02, -1.6101e-02,  5.4258e-02,\n",
              "          2.1216e-02,  7.7140e-02, -1.8668e-02, -1.2851e-01,  6.7974e-02,\n",
              "          1.7153e-02,  1.0572e-01,  5.4604e-02,  5.5624e-02,  2.2569e-02,\n",
              "          3.5462e-02,  7.4202e-02,  5.0939e-03,  4.7178e-02, -1.7340e-02,\n",
              "          2.3107e-02, -6.6289e-03, -1.8340e-02, -5.1042e-02,  7.8133e-03,\n",
              "          3.4082e-02, -1.1932e-02]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k08MAGZ326V"
      },
      "source": [
        "# ======================================\n",
        "# relu는 맨 마지막 레이어에서 빼는 것이 좋다.\n",
        "# ======================================\n",
        "model = torch.nn.Sequential(linear1,relu,dropout,\n",
        "                            linear2,relu,dropout,\n",
        "                            linear3,relu,dropout,\n",
        "                            linear4,relu,dropout,\n",
        "                            linear5).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9WQWlFdcKaH"
      },
      "source": [
        "# 손실함수와 최적화 함수\n",
        "loss = torch.nn.MSELoss().to(device) # softmax 내부적으로 계산\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQu5p_pTcRFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd5632f-e321-4400-e7a1-f371d4d3aeb8"
      },
      "source": [
        "train_X=train_X.to(device)\n",
        "train_Y=train_Y.to(device)\n",
        "\n",
        "for stop in range(20000):\n",
        "    \n",
        "    # 그래디언트 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # Forward 계산\n",
        "    hypothesis = model(train_X)\n",
        "    # Error 계산\n",
        "    cost = loss(hypothesis, train_Y)\n",
        "    # Backward 계산 \n",
        "    cost.backward()\n",
        "    # 가중치 갱신\n",
        "    optimizer.step()\n",
        "\n",
        "    if stop % 100 == 0:\n",
        "        print(stop, cost.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 578.6893920898438\n",
            "100 49.829471588134766\n",
            "200 30.076013565063477\n",
            "300 25.092615127563477\n",
            "400 23.269973754882812\n",
            "500 21.561586380004883\n",
            "600 21.523014068603516\n",
            "700 20.211715698242188\n",
            "800 19.287485122680664\n",
            "900 19.056116104125977\n",
            "1000 17.732154846191406\n",
            "1100 17.444103240966797\n",
            "1200 17.473554611206055\n",
            "1300 15.96004581451416\n",
            "1400 14.779253005981445\n",
            "1500 15.227150917053223\n",
            "1600 14.3407621383667\n",
            "1700 14.289031982421875\n",
            "1800 13.875423431396484\n",
            "1900 12.83409309387207\n",
            "2000 11.961563110351562\n",
            "2100 11.376832962036133\n",
            "2200 11.257830619812012\n",
            "2300 12.111675262451172\n",
            "2400 11.445505142211914\n",
            "2500 10.903603553771973\n",
            "2600 9.763093948364258\n",
            "2700 9.259719848632812\n",
            "2800 9.470353126525879\n",
            "2900 9.011978149414062\n",
            "3000 9.103261947631836\n",
            "3100 9.478164672851562\n",
            "3200 8.177597045898438\n",
            "3300 8.849291801452637\n",
            "3400 8.75355052947998\n",
            "3500 7.775436878204346\n",
            "3600 7.939126014709473\n",
            "3700 7.931691646575928\n",
            "3800 7.638484001159668\n",
            "3900 8.284515380859375\n",
            "4000 7.368402481079102\n",
            "4100 7.524023532867432\n",
            "4200 8.392068862915039\n",
            "4300 7.390173435211182\n",
            "4400 7.154234886169434\n",
            "4500 6.850376605987549\n",
            "4600 7.133711814880371\n",
            "4700 6.8514204025268555\n",
            "4800 6.752242565155029\n",
            "4900 6.486209869384766\n",
            "5000 7.356142044067383\n",
            "5100 6.559556007385254\n",
            "5200 7.53941011428833\n",
            "5300 6.314019680023193\n",
            "5400 6.290729999542236\n",
            "5500 5.781585693359375\n",
            "5600 5.922543525695801\n",
            "5700 5.7858076095581055\n",
            "5800 5.725240707397461\n",
            "5900 5.491002559661865\n",
            "6000 5.893402576446533\n",
            "6100 5.5576558113098145\n",
            "6200 6.145194053649902\n",
            "6300 5.366733551025391\n",
            "6400 5.634309768676758\n",
            "6500 6.487092018127441\n",
            "6600 5.6216630935668945\n",
            "6700 5.190797805786133\n",
            "6800 5.192901134490967\n",
            "6900 5.597962379455566\n",
            "7000 5.176556587219238\n",
            "7100 5.080709457397461\n",
            "7200 4.6358747482299805\n",
            "7300 4.573681354522705\n",
            "7400 5.117042064666748\n",
            "7500 5.094754695892334\n",
            "7600 4.667609214782715\n",
            "7700 5.214155197143555\n",
            "7800 4.6115288734436035\n",
            "7900 5.35542631149292\n",
            "8000 4.713544845581055\n",
            "8100 4.6300764083862305\n",
            "8200 4.820687770843506\n",
            "8300 4.751025676727295\n",
            "8400 6.31205940246582\n",
            "8500 5.840806484222412\n",
            "8600 4.705881118774414\n",
            "8700 4.48360538482666\n",
            "8800 4.398677349090576\n",
            "8900 4.284414291381836\n",
            "9000 4.705260276794434\n",
            "9100 4.277826309204102\n",
            "9200 4.2335357666015625\n",
            "9300 4.624959468841553\n",
            "9400 4.156671047210693\n",
            "9500 4.246293544769287\n",
            "9600 3.942302942276001\n",
            "9700 4.09861946105957\n",
            "9800 4.242585182189941\n",
            "9900 4.644818305969238\n",
            "10000 3.9965922832489014\n",
            "10100 3.725734233856201\n",
            "10200 3.951169729232788\n",
            "10300 4.220381259918213\n",
            "10400 4.060612678527832\n",
            "10500 3.8649022579193115\n",
            "10600 3.7045516967773438\n",
            "10700 7.677872657775879\n",
            "10800 3.8908743858337402\n",
            "10900 4.142667293548584\n",
            "11000 3.7744719982147217\n",
            "11100 3.763784170150757\n",
            "11200 4.6809258460998535\n",
            "11300 3.7561686038970947\n",
            "11400 3.9463837146759033\n",
            "11500 3.618116617202759\n",
            "11600 3.5376040935516357\n",
            "11700 3.846701145172119\n",
            "11800 4.020316123962402\n",
            "11900 3.5691654682159424\n",
            "12000 3.4103894233703613\n",
            "12100 3.941664457321167\n",
            "12200 3.612889528274536\n",
            "12300 4.555578231811523\n",
            "12400 3.7749135494232178\n",
            "12500 3.8875365257263184\n",
            "12600 3.8750569820404053\n",
            "12700 3.59464430809021\n",
            "12800 3.6502251625061035\n",
            "12900 3.6608145236968994\n",
            "13000 3.7727394104003906\n",
            "13100 3.5974385738372803\n",
            "13200 3.560102939605713\n",
            "13300 3.735708475112915\n",
            "13400 4.1975836753845215\n",
            "13500 3.560574769973755\n",
            "13600 3.56362247467041\n",
            "13700 3.6407673358917236\n",
            "13800 3.6145334243774414\n",
            "13900 3.4989445209503174\n",
            "14000 3.487046480178833\n",
            "14100 3.4881324768066406\n",
            "14200 3.7549755573272705\n",
            "14300 3.688051700592041\n",
            "14400 3.7971343994140625\n",
            "14500 3.5920865535736084\n",
            "14600 3.542569875717163\n",
            "14700 3.169743537902832\n",
            "14800 3.4772329330444336\n",
            "14900 3.2692928314208984\n",
            "15000 3.2541658878326416\n",
            "15100 3.3411223888397217\n",
            "15200 3.5864086151123047\n",
            "15300 3.5871877670288086\n",
            "15400 3.5183753967285156\n",
            "15500 3.4795186519622803\n",
            "15600 3.350181818008423\n",
            "15700 3.104173421859741\n",
            "15800 3.0974230766296387\n",
            "15900 3.22902250289917\n",
            "16000 3.8287785053253174\n",
            "16100 3.1233580112457275\n",
            "16200 3.903722047805786\n",
            "16300 3.18951153755188\n",
            "16400 3.329714298248291\n",
            "16500 3.0602853298187256\n",
            "16600 3.4676437377929688\n",
            "16700 3.1846511363983154\n",
            "16800 3.183210849761963\n",
            "16900 3.2519116401672363\n",
            "17000 2.940998077392578\n",
            "17100 3.154282331466675\n",
            "17200 3.2866146564483643\n",
            "17300 3.4873859882354736\n",
            "17400 3.1137900352478027\n",
            "17500 3.093808174133301\n",
            "17600 3.1151821613311768\n",
            "17700 3.149482250213623\n",
            "17800 3.0880377292633057\n",
            "17900 3.040980815887451\n",
            "18000 3.1797780990600586\n",
            "18100 3.1476573944091797\n",
            "18200 3.151305675506592\n",
            "18300 2.962611436843872\n",
            "18400 3.0499491691589355\n",
            "18500 3.009478807449341\n",
            "18600 3.0775842666625977\n",
            "18700 3.64288067817688\n",
            "18800 3.4914402961730957\n",
            "18900 26.86752700805664\n",
            "19000 18.38509178161621\n",
            "19100 15.680601119995117\n",
            "19200 13.767707824707031\n",
            "19300 13.489907264709473\n",
            "19400 12.692239761352539\n",
            "19500 10.812118530273438\n",
            "19600 10.48403263092041\n",
            "19700 9.87514877319336\n",
            "19800 9.286234855651855\n",
            "19900 9.20195484161377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOrY7qtNMQx-"
      },
      "source": [
        "xy2_x=np.array(data2, dtype=np.float32)\n",
        "\n",
        "test_X = torch.FloatTensor(xy2_x[:,1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlVFqtJGMe81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f5839d-ac86-4825-80ea-8a8f97902ca9"
      },
      "source": [
        "print(test_X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1043.0000,    7.0000,   30.0000,  ...,    2.0000,   63.0200,\n",
            "            3.0000],\n",
            "        [1043.0000,    8.0000,    0.0000,  ...,    2.3000,   61.5400,\n",
            "            5.0000],\n",
            "        [1043.0000,    8.0000,   30.0000,  ...,    2.4000,   57.3400,\n",
            "            6.0000],\n",
            "        ...,\n",
            "        [1094.0000,   22.0000,   30.0000,  ...,    2.2000,   66.7800,\n",
            "           -4.0000],\n",
            "        [1094.0000,   23.0000,    0.0000,  ...,    2.1000,   67.7200,\n",
            "           -4.0000],\n",
            "        [1094.0000,   23.0000,   30.0000,  ...,    2.1000,   67.7000,\n",
            "           -4.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_SQp0GxdJfc"
      },
      "source": [
        "# Test the model using test sets\n",
        "test_X=test_X.to(device)\n",
        "with torch.no_grad():\n",
        "    model.eval()  # 주의사항 (dropout=False)\n",
        "    prediction = model(test_X)\n",
        "    correct_prediction = torch.argmax(prediction, 1)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpdi_NQ8M23W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "1b5f9a92-6a29-4a93-ce48-b29cd2aef5a0"
      },
      "source": [
        "result=correct_prediction.cpu().numpy()\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-39dd3dffbdb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unique'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGeBRWURiQAM"
      },
      "source": [
        "submit['TARGET']=result\n",
        "submit.to_csv('result_submit.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}